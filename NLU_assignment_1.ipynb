{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU-assignment-1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoZanella/NLU-assignement-1/blob/main/NLU_assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O99OsUUONTEK"
      },
      "source": [
        "# NLU assignment n.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "141aPErmO-H6"
      },
      "source": [
        "## Part A: Working with Dependency Graphs\n",
        "The objective of the assignment is to learn how to work with dependency graphs by defining functions.\n",
        "\n",
        "Read [spaCy documentation on dependency parser](https://spacy.io/api/dependencyparser) to learn provided methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJVn2Qwsv6Vu"
      },
      "source": [
        "# Imports\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# HELPER FUNCTIONS\n",
        "# get the doc from a sentence\n",
        "def doc_of(sentence: str) -> spacy.tokens.Doc:\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  return nlp(sentence)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "jOKd8l97MobZ",
        "outputId": "7aecb57c-8559-49e1-d0ab-763113db3ec5"
      },
      "source": [
        "# Example sentence (for testing)\n",
        "example = \"Credit and mortgage account holders must submit their requests.\"\n",
        "# Example sentence visualization\n",
        "displacy.render(doc_of(example), style='dep', jupyter=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aba4bd7bcb654643b99690b1fe20828e-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Credit</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">mortgage</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">account</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">holders</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">must</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">submit</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">their</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">requests.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M215.0,266.5 L223.0,254.5 207.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-2\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,266.5 L403.0,254.5 387.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aba4bd7bcb654643b99690b1fe20828e-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aba4bd7bcb654643b99690b1fe20828e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1445.0,266.5 L1453.0,254.5 1437.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kDDUX8DPF_5"
      },
      "source": [
        "### Task A1\n",
        "Extract a path of dependency relations from the ROOT to a token\n",
        "\n",
        "The best way to match is from below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwWcVJUiFJNE"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "\n",
        "def dependency_path(sentence: str):\n",
        "  doc = doc_of(sentence)\n",
        "  root = doc[:].root\n",
        "  paths = {root: []}\n",
        "  tokens = deque([root])\n",
        "  # BFS search from the root\n",
        "  while tokens:\n",
        "    token = tokens.popleft()\n",
        "    paths[token] = [*paths[token.head], token.dep_]\n",
        "    tokens.extend(token.children)\n",
        "  return paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hffSPxUuxNb9"
      },
      "source": [
        "#### Testing A1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIsi5oDFGBE_",
        "outputId": "2db0ed2a-bdbb-446b-ddd2-e265c7190c06"
      },
      "source": [
        "# Task A1 testing\n",
        "paths = dependency_path(example)\n",
        "for token in paths:\n",
        "  print(f\"{token}: {paths[token]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "submit: ['ROOT']\n",
            "holders: ['ROOT', 'nsubj']\n",
            "must: ['ROOT', 'aux']\n",
            "requests: ['ROOT', 'dobj']\n",
            ".: ['ROOT', 'punct']\n",
            "account: ['ROOT', 'nsubj', 'compound']\n",
            "their: ['ROOT', 'dobj', 'poss']\n",
            "Credit: ['ROOT', 'nsubj', 'compound', 'nmod']\n",
            "and: ['ROOT', 'nsubj', 'compound', 'nmod', 'cc']\n",
            "mortgage: ['ROOT', 'nsubj', 'compound', 'nmod', 'conj']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH-y2WbUPZu5"
      },
      "source": [
        "### Task A2\n",
        "Extract subtree of a dependents given a token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiQZITfAVb_2"
      },
      "source": [
        "def dependents_tree(sentence: str):\n",
        "  doc = doc_of(sentence)\n",
        "  return {token: [*token.subtree] for token in doc}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEw4DM64Wc98"
      },
      "source": [
        "#### Testing A2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dM7MGkhWfrk",
        "outputId": "b07320e5-0993-44ac-fb06-c8142b4912a0"
      },
      "source": [
        "# Task A2 testing\n",
        "paths = dependents_tree(example)\n",
        "for token in paths:\n",
        "  print(f\"{token}: {paths[token]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Credit: [Credit, and, mortgage]\n",
            "and: [and]\n",
            "mortgage: [mortgage]\n",
            "account: [Credit, and, mortgage, account]\n",
            "holders: [Credit, and, mortgage, account, holders]\n",
            "must: [must]\n",
            "submit: [Credit, and, mortgage, account, holders, must, submit, their, requests, .]\n",
            "their: [their]\n",
            "requests: [their, requests]\n",
            ".: [.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfn7btkXPfSs"
      },
      "source": [
        "### Task A3\n",
        "Check if a given list of tokens (ordered list of words from the sentence) forms a subtree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtcZMNNrXHOI"
      },
      "source": [
        "def is_dependents_tree(sentence: str, sequence: [str]):\n",
        "  doc = doc_of(sentence)\n",
        "  sequence_set = set(sequence)\n",
        "  # We use the first word as anchor to find the within-sequence root. With \n",
        "  # repetitions of the anchor word, at least one should have a within-sequence\n",
        "  # root that is the root of the sequence\n",
        "  anchor = sequence[0]\n",
        "  for token in doc:\n",
        "    if token.text == anchor:\n",
        "      # Find the within-sequence root\n",
        "      root = token\n",
        "      while root != root.head and root.head.text in sequence_set:\n",
        "        root = root.head\n",
        "      # Check if the within-sequence root is the sequence root\n",
        "      if sequence == [token.text for token in root.subtree]:\n",
        "        return True\n",
        "  return False\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjzWAMsOnXz9"
      },
      "source": [
        "#### Testing A3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMe6B-ZtngtJ",
        "outputId": "190c24e2-bad6-4b2c-d131-eea9a6f2633f"
      },
      "source": [
        "# Task A3 testing\n",
        "trees = [[\"Credit\", \"and\", \"mortgage\"],\n",
        "         [\"and\", \"Credit\", \"mortgage\"],\n",
        "         [\"must\", \"submit\", \"their\"]]\n",
        "print(example)\n",
        "for tree in trees:\n",
        "  print(f\"{tree}: {is_dependents_tree(example, tree)}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Credit and mortgage account holders must submit their requests.\n",
            "['Credit', 'and', 'mortgage']: True\n",
            "['and', 'Credit', 'mortgage']: False\n",
            "['must', 'submit', 'their']: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPiyRSXTPloa"
      },
      "source": [
        "### Task A4\n",
        " Identify the head of a span, given its tokens: find the head/root of a phrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aCJUdI7tn0P"
      },
      "source": [
        "def head_of(sentence: str):\n",
        "  doc = doc_of(sentence)\n",
        "  return doc[:].root"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90yc_kmqt9yv"
      },
      "source": [
        "#### Testing A4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FKkifJpt_8H",
        "outputId": "38111809-a45b-402a-a9bd-831389cd4280"
      },
      "source": [
        "# Task A4 testing\n",
        "examples = [example, \"man with a telescope\", \"has the tower tripped down?\"]\n",
        "for ex in examples:\n",
        "  print(f\"{ex}: {head_of(ex)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Credit and mortgage account holders must submit their requests.: submit\n",
            "man with a telescope: man\n",
            "has the tower tripped down?: tripped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAtVedHmPohR"
      },
      "source": [
        "### Task A5\n",
        "Extract sentence subject, direct object and indirect object spans. Each span lenght is 1, for the single word.\n",
        "\n",
        "`iobj` is [not a parsed dependency](https://spacy.io/models/en): `dative` is parsed instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPwV0Q1ZvdB1"
      },
      "source": [
        "def interesting_spans(sentence: str):\n",
        "  doc = doc_of(sentence)\n",
        "  spans = {'nsubj': [], 'dobj': [], 'dative':[]}\n",
        "  for token in doc:\n",
        "    if token.dep_ == 'nsubj' or token.dep_ == 'dobj' or token.dep_ == 'dative':\n",
        "      subtree = [*token.subtree]\n",
        "      span = doc[subtree[0].i:subtree[-1].i+1]\n",
        "      spans[token.dep_].append(span)\n",
        "  return spans"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2loKndTy1fA"
      },
      "source": [
        "#### Testing A5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ajWGlYy4hN",
        "outputId": "eb010ada-ef04-448a-cbbc-43512f6f5787"
      },
      "source": [
        "print(interesting_spans(example))\n",
        "print(interesting_spans(\"I saw the man.\"))\n",
        "print(interesting_spans(\"I read her the letter\"))\n",
        "print(interesting_spans(\"They normally give refugees shelter.\"))\n",
        "print(interesting_spans(\"We booked her the cheapest morning flight to Miami.\"))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'nsubj': [Credit and mortgage account holders], 'dobj': [their requests], 'dative': []}\n",
            "{'nsubj': [I], 'dobj': [the man], 'dative': []}\n",
            "{'nsubj': [I], 'dobj': [the letter], 'dative': [her]}\n",
            "{'nsubj': [They], 'dobj': [shelter], 'dative': [refugees]}\n",
            "{'nsubj': [We], 'dobj': [her, the cheapest morning flight to Miami], 'dative': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11UJZwWaPyNv"
      },
      "source": [
        "## Part B: Training Transition-Based Dependency Parser\n",
        "This part is optional and advanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y56ek6VvSxYE",
        "outputId": "96007751-7473-4016-d2cc-fd6af8394adb"
      },
      "source": [
        "# Imports\n",
        "import nltk\n",
        "from nltk.parse.transitionparser import TransitionParser\n",
        "from nltk.parse import DependencyEvaluator\n",
        "\n",
        "# Download treebank\n",
        "from nltk.corpus import dependency_treebank\n",
        "nltk.download('dependency_treebank')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package dependency_treebank to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package dependency_treebank is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0ZZdcmyP_lk"
      },
      "source": [
        "### Task B1-B3\n",
        "Modify [NLTK Transition parser](https://github.com/nltk/nltk/blob/develop/nltk/parse/transitionparser.py)'s `Configuration` class to use better features.\n",
        "\n",
        "Replace `SVM` classifier with an alternative of your choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ajr4plNA0WC",
        "outputId": "3eca3de6-b84b-4c5c-e380-23eec7948f75"
      },
      "source": [
        "!pip install fasttext\n",
        "!wget -nc https://github.com/MatteoZanella/NLU-assignement-1/raw/main/data/cc.en.6.bin.7z\n",
        "!7za e cc.en.6.bin.7z -aos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (54.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
            "File ‘cc.en.6.bin.7z’ already there; not retrieving.\n",
            "\n",
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 100249997 bytes (96 MiB)\n",
            "\n",
            "Extracting archive: cc.en.6.bin.7z\n",
            "--\n",
            "Path = cc.en.6.bin.7z\n",
            "Type = 7z\n",
            "Physical Size = 100249997\n",
            "Headers Size = 130\n",
            "Method = LZMA2:24\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  4% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% . cc.en.6.bin\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       181176312\n",
            "Compressed: 100249997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkwZpLKJHAR3"
      },
      "source": [
        "### Not executable on the Colab notebook - Snippet to convert the 300 features model into a 6 features model ###\n",
        "# import fasttext\n",
        "# import fasttext.util\n",
        "# fasttext.util.download_model('en', if_exists='ignore')\n",
        "# ft = fasttext.load_model('cc.en.300.bin')\n",
        "# fasttext.util.reduce_model(ft, 6)\n",
        "# ft.save_model('cc.en.6.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_jIUizUyq5G"
      },
      "source": [
        "import tempfile\n",
        "import pickle\n",
        "\n",
        "from os import remove\n",
        "from copy import deepcopy\n",
        "from operator import itemgetter\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from scipy import sparse\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "\n",
        "from nltk.parse import ParserI, DependencyGraph, DependencyEvaluator\n",
        "\n",
        "\n",
        "class NxtConfiguration(object):\n",
        "    \"\"\"\n",
        "    Class for holding configuration which is the partial analysis of the input sentence.\n",
        "    The transition based parser aims at finding set of operators that transfer the initial\n",
        "    configuration to the terminal configuration.\n",
        "    The configuration includes:\n",
        "        - Stack: for storing partially proceeded words\n",
        "        - Buffer: for storing remaining input words\n",
        "        - Set of arcs: for storing partially built dependency tree\n",
        "    This class also provides a method to represent a configuration as list of features.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dep_graph):\n",
        "        \"\"\"\n",
        "        :param dep_graph: the representation of an input in the form of dependency graph.\n",
        "        :type dep_graph: DependencyGraph where the dependencies are not specified.\n",
        "        \"\"\"\n",
        "        # dep_graph.nodes contain list of token for a sentence\n",
        "        self.stack = [0]  # The root element\n",
        "        self.buffer = list(range(1, len(dep_graph.nodes)))  # The rest is in the buffer\n",
        "        self.arcs = []  # empty set of arc\n",
        "        self._tokens = dep_graph.nodes\n",
        "        self._max_address = len(self.buffer)\n",
        "\n",
        "    def __str__(self):\n",
        "        return (\n",
        "            \"Stack : \"\n",
        "            + str(self.stack)\n",
        "            + \"  Buffer : \"\n",
        "            + str(self.buffer)\n",
        "            + \"   Arcs : \"\n",
        "            + str(self.arcs)\n",
        "        )\n",
        "\n",
        "    def _check_informative(self, feat, flag=False):\n",
        "        \"\"\"\n",
        "        Check whether a feature is informative\n",
        "        The flag control whether \"_\" is informative or not\n",
        "        \"\"\"\n",
        "        if feat is None or feat == \"\" or (not flag and feat == \"_\"):\n",
        "            return None\n",
        "        else:\n",
        "          return feat\n",
        "\n",
        "    def extract_features(self, stack_count=2, buffer_count=3):\n",
        "        \"\"\"\n",
        "        Extract the set of features for the current configuration.\n",
        "        :return: list(str)\n",
        "        \"\"\"\n",
        "        # Stack to stack of tokens\n",
        "        stack_tokens = [self._check_informative(self._tokens[idx]['word']) for idx in self.stack]\n",
        "        # Extend with empty if too small\n",
        "        for _ in range(len(stack_tokens), stack_count+1):\n",
        "          stack_tokens.insert(0, None)\n",
        "        # Compact the ones outside the count as a single list\n",
        "        tail = [stack_tokens[:-stack_count]]\n",
        "        stack_tokens = stack_tokens[-stack_count:]\n",
        "        stack_tokens.extend(tail)\n",
        "\n",
        "        # Buffer to buffer of tokens\n",
        "        buffer_tokens = [self._check_informative(self._tokens[idx]['word']) for idx in self.buffer]\n",
        "        # Extend with empty if too small\n",
        "        for _ in range(len(buffer_tokens), buffer_count+1):\n",
        "          buffer_tokens.append(None)\n",
        "        # Compact the ones outside the count as a single list\n",
        "        tail = [buffer_tokens[buffer_count:]]\n",
        "        buffer_tokens = buffer_tokens[:buffer_count]\n",
        "        buffer_tokens.extend(tail)\n",
        "\n",
        "        # Stack POS\n",
        "        stack_tags = [self._check_informative(self._tokens[idx]['tag']) for idx in self.stack[-stack_count:]]\n",
        "        for _ in range(len(stack_tags), stack_count+1):\n",
        "          stack_tags.insert(0, None)\n",
        "        # Buffer POS\n",
        "        buffer_tags = [self._check_informative(self._tokens[idx]['tag']) for idx in self.buffer[:buffer_count]]\n",
        "        for _ in range(len(buffer_tags), buffer_count+1):\n",
        "          buffer_tags.append(None)\n",
        "\n",
        "        stack_tokens.extend(buffer_tokens)\n",
        "        stack_tokens.extend(stack_tags)\n",
        "        stack_tokens.extend(buffer_tags)\n",
        "        return stack_tokens\n",
        "\n",
        "\n",
        "class Transition(object):\n",
        "    \"\"\"\n",
        "    This class defines a set of transition which is applied to a configuration to get another configuration\n",
        "    Note that for different parsing algorithm, the transition is different.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define set of transitions\n",
        "    LEFT_ARC = \"LEFTARC\"\n",
        "    RIGHT_ARC = \"RIGHTARC\"\n",
        "    SHIFT = \"SHIFT\"\n",
        "    REDUCE = \"REDUCE\"\n",
        "\n",
        "    def __init__(self, alg_option):\n",
        "        \"\"\"\n",
        "        :param alg_option: the algorithm option of this parser. Currently support `arc-standard` and `arc-eager` algorithm\n",
        "        :type alg_option: str\n",
        "        \"\"\"\n",
        "        self._algo = alg_option\n",
        "        if alg_option not in [\n",
        "            TransitionParser.ARC_STANDARD,\n",
        "            TransitionParser.ARC_EAGER,\n",
        "        ]:\n",
        "            raise ValueError(\n",
        "                \" Currently we only support %s and %s \"\n",
        "                % (TransitionParser.ARC_STANDARD, TransitionParser.ARC_EAGER)\n",
        "            )\n",
        "\n",
        "    def left_arc(self, conf, relation):\n",
        "        \"\"\"\n",
        "        Note that the algorithm for left-arc is quite similar except for precondition for both arc-standard and arc-eager\n",
        "            :param configuration: is the current configuration\n",
        "            :return : A new configuration or -1 if the pre-condition is not satisfied\n",
        "        \"\"\"\n",
        "        if (len(conf.buffer) <= 0) or (len(conf.stack) <= 0):\n",
        "            return -1\n",
        "        if conf.buffer[0] == 0:\n",
        "            # here is the Root element\n",
        "            return -1\n",
        "\n",
        "        idx_wi = conf.stack[len(conf.stack) - 1]\n",
        "\n",
        "        flag = True\n",
        "        if self._algo == TransitionParser.ARC_EAGER:\n",
        "            for (idx_parent, r, idx_child) in conf.arcs:\n",
        "                if idx_child == idx_wi:\n",
        "                    flag = False\n",
        "\n",
        "        if flag:\n",
        "            conf.stack.pop()\n",
        "            idx_wj = conf.buffer[0]\n",
        "            conf.arcs.append((idx_wj, relation, idx_wi))\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "    def right_arc(self, conf, relation):\n",
        "        \"\"\"\n",
        "        Note that the algorithm for right-arc is DIFFERENT for arc-standard and arc-eager\n",
        "            :param configuration: is the current configuration\n",
        "            :return : A new configuration or -1 if the pre-condition is not satisfied\n",
        "        \"\"\"\n",
        "        if (len(conf.buffer) <= 0) or (len(conf.stack) <= 0):\n",
        "            return -1\n",
        "        if self._algo == TransitionParser.ARC_STANDARD:\n",
        "            idx_wi = conf.stack.pop()\n",
        "            idx_wj = conf.buffer[0]\n",
        "            conf.buffer[0] = idx_wi\n",
        "            conf.arcs.append((idx_wi, relation, idx_wj))\n",
        "        else:  # arc-eager\n",
        "            idx_wi = conf.stack[len(conf.stack) - 1]\n",
        "            idx_wj = conf.buffer.pop(0)\n",
        "            conf.stack.append(idx_wj)\n",
        "            conf.arcs.append((idx_wi, relation, idx_wj))\n",
        "\n",
        "    def reduce(self, conf):\n",
        "        \"\"\"\n",
        "        Note that the algorithm for reduce is only available for arc-eager\n",
        "            :param configuration: is the current configuration\n",
        "            :return : A new configuration or -1 if the pre-condition is not satisfied\n",
        "        \"\"\"\n",
        "\n",
        "        if self._algo != TransitionParser.ARC_EAGER:\n",
        "            return -1\n",
        "        if len(conf.stack) <= 0:\n",
        "            return -1\n",
        "\n",
        "        idx_wi = conf.stack[len(conf.stack) - 1]\n",
        "        flag = False\n",
        "        for (idx_parent, r, idx_child) in conf.arcs:\n",
        "            if idx_child == idx_wi:\n",
        "                flag = True\n",
        "        if flag:\n",
        "            conf.stack.pop()  # reduce it\n",
        "        else:\n",
        "            return -1\n",
        "\n",
        "    def shift(self, conf):\n",
        "        \"\"\"\n",
        "        Note that the algorithm for shift is the SAME for arc-standard and arc-eager\n",
        "            :param configuration: is the current configuration\n",
        "            :return : A new configuration or -1 if the pre-condition is not satisfied\n",
        "        \"\"\"\n",
        "        if len(conf.buffer) <= 0:\n",
        "            return -1\n",
        "        idx_wi = conf.buffer.pop(0)\n",
        "        conf.stack.append(idx_wi)\n",
        "\n",
        "\n",
        "class NxtTransitionParser(ParserI):\n",
        "\n",
        "    \"\"\"\n",
        "    Class for transition based parser. Implement \"arc-eager\"\n",
        "    \"\"\"\n",
        "\n",
        "    ARC_EAGER = \"arc-eager\"\n",
        "\n",
        "    def __init__(self, classifier='svm'):\n",
        "        self._classifier = classifier\n",
        "        self._algorithm = self.ARC_EAGER\n",
        "        self._ft = fasttext.load_model('cc.en.6.bin')\n",
        "        self._label_encoder = preprocessing.LabelEncoder()\n",
        "        self._pos_encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "        self._pos_encoder.fit([['CC'],[','],['CD'],['DT'],['EX'],['FW'],['IN'],\n",
        "                               ['JJ'],['JJR'],['JJS'],['LS'],['MD'],['NN'],\n",
        "                               ['NNPS'],['NNP'],['NNPS'],['PDT'],['POS'],\n",
        "                               ['PRP'],['PRP$'],['RB'],['RBR'],['RBS'],['RP'],\n",
        "                               ['SYM'],['TO'],['UH'],['VB'],['VBD'],['VBG'],\n",
        "                               ['VBN'],['VBP'],['VBZ'],['WP'],['WDT'],['WP$'],['WRB']])\n",
        "\n",
        "\n",
        "    def _get_dep_relation(self, idx_parent, idx_child, depgraph):\n",
        "        p_node = depgraph.nodes[idx_parent]\n",
        "        c_node = depgraph.nodes[idx_child]\n",
        "\n",
        "        if c_node[\"word\"] is None:\n",
        "            return None  # Root word\n",
        "\n",
        "        if c_node[\"head\"] == p_node[\"address\"]:\n",
        "            return c_node[\"rel\"]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def _convert_to_binary_features(self, features, discount=0.6):\n",
        "        \"\"\"\n",
        "        :param features: list of feature string which is needed to convert to binary features\n",
        "        :type features: list(str)\n",
        "        :return : string of binary features in libsvm format  which is 'featureID:value' pairs\n",
        "        \"\"\"\n",
        "        TAGS_COUNT = 6\n",
        "        for idx, feature in enumerate(features):\n",
        "          if idx >= len(features) - TAGS_COUNT:\n",
        "            features[idx] = self._pos_encoder.transform([[feature]]).toarray()\n",
        "          if type(feature) is list:\n",
        "            discounts = np.power(discount, np.arange(0,len(feature)))[:,np.newaxis]\n",
        "            feature = np.array([self._to_fasttext(token) for token in feature]) * discounts\n",
        "            features[idx] = np.sum(feature, axis=0)\n",
        "          else:\n",
        "            features[idx] = self._to_fasttext(feature)\n",
        "\n",
        "        return np.array(features).flatten()\n",
        "    \n",
        "    def _to_fasttext(self, token):\n",
        "      if token is None:\n",
        "        return np.zeros(self._ft.get_dimension())\n",
        "      else:\n",
        "        return self._ft[token]\n",
        "\n",
        "    def _is_projective(self, depgraph):\n",
        "        arc_list = []\n",
        "        for key in depgraph.nodes:\n",
        "            node = depgraph.nodes[key]\n",
        "\n",
        "            if \"head\" in node:\n",
        "                childIdx = node[\"address\"]\n",
        "                parentIdx = node[\"head\"]\n",
        "                if parentIdx is not None:\n",
        "                    arc_list.append((parentIdx, childIdx))\n",
        "\n",
        "        for (parentIdx, childIdx) in arc_list:\n",
        "            # Ensure that childIdx < parentIdx\n",
        "            if childIdx > parentIdx:\n",
        "                temp = childIdx\n",
        "                childIdx = parentIdx\n",
        "                parentIdx = temp\n",
        "            for k in range(childIdx + 1, parentIdx):\n",
        "                for m in range(len(depgraph.nodes)):\n",
        "                    if (m < childIdx) or (m > parentIdx):\n",
        "                        if (k, m) in arc_list:\n",
        "                            return False\n",
        "                        if (m, k) in arc_list:\n",
        "                            return False\n",
        "        return True\n",
        "\n",
        "    def _training_set(self, depgraphs):\n",
        "        \"\"\"\n",
        "        Create the training set.\n",
        "        \"\"\"\n",
        "        operation = Transition(self.ARC_EAGER)\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "\n",
        "        for depgraph in depgraphs:\n",
        "            if not self._is_projective(depgraph):\n",
        "                continue\n",
        "\n",
        "            conf = NxtConfiguration(depgraph)\n",
        "            while len(conf.buffer) > 0:\n",
        "                b0 = conf.buffer[0]\n",
        "                features = conf.extract_features()\n",
        "                binary_features = self._convert_to_binary_features(features)\n",
        "                \n",
        "                x_train.append(binary_features)\n",
        "                if len(conf.stack) > 0:\n",
        "                    s0 = conf.stack[len(conf.stack) - 1]\n",
        "                    # Left-arc operation\n",
        "                    rel = self._get_dep_relation(b0, s0, depgraph)\n",
        "                    if rel is not None:\n",
        "                        key = Transition.LEFT_ARC + \":\" + rel\n",
        "                        operation.left_arc(conf, rel)\n",
        "                        y_train.append(key)\n",
        "                        continue\n",
        "\n",
        "                    # Right-arc operation\n",
        "                    rel = self._get_dep_relation(s0, b0, depgraph)\n",
        "                    if rel is not None:\n",
        "                        key = Transition.RIGHT_ARC + \":\" + rel\n",
        "                        operation.right_arc(conf, rel)\n",
        "                        y_train.append(key)\n",
        "                        continue\n",
        "\n",
        "                    # reduce operation\n",
        "                    flag = False\n",
        "                    for k in range(s0):\n",
        "                        if self._get_dep_relation(k, b0, depgraph) is not None:\n",
        "                            flag = True\n",
        "                        if self._get_dep_relation(b0, k, depgraph) is not None:\n",
        "                            flag = True\n",
        "                    if flag:\n",
        "                        key = Transition.REDUCE\n",
        "                        operation.reduce(conf)\n",
        "                        y_train.append(key)\n",
        "                        continue\n",
        "\n",
        "                # Shift operation as the default\n",
        "                key = Transition.SHIFT\n",
        "                operation.shift(conf)\n",
        "                y_train.append(key)\n",
        "\n",
        "        x_train = np.array(x_train)\n",
        "        y_train = np.array(y_train)\n",
        "        self._label_encoder.fit(y_train)\n",
        "        y_train = self._label_encoder.transform(y_train)\n",
        "        return x_train, y_train\n",
        "\n",
        "    def train(self, depgraphs, modelfile, verbose=True):\n",
        "        \"\"\"\n",
        "        :param depgraphs : list of DependencyGraph as the training data\n",
        "        :type depgraphs : DependencyGraph\n",
        "        :param modelfile : file name to save the trained model\n",
        "        :type modelfile : str\n",
        "        \"\"\"\n",
        "        \n",
        "        # Load the training set\n",
        "        x_train, y_train = self._training_set(depgraphs)\n",
        "\n",
        "        # Fit the model\n",
        "        if self._classifier == 'mlp':\n",
        "          model = MLPClassifier(solver='adam', alpha=1e-6, learning_rate='adaptive', learning_rate_init=0.01, hidden_layer_sizes=(64, 32, 16), random_state=1)\n",
        "        elif self._classifier == 'svm':\n",
        "          model = SVC(class_weight='balanced')\n",
        "        else:\n",
        "          raise Exception(f\"No model with such name: {self._classifier}. Try 'svm' or 'mlp'\")\n",
        "        model.fit(x_train, y_train)\n",
        "        # Save the model to file name (as pickle)\n",
        "        pickle.dump(model, open(modelfile, \"wb\"))\n",
        "\n",
        "    def parse(self, depgraphs, modelFile):\n",
        "        \"\"\"\n",
        "        :param depgraphs: the list of test sentence, each sentence is represented as a dependency graph where the 'head' information is dummy\n",
        "        :type depgraphs: list(DependencyGraph)\n",
        "        :param modelfile: the model file\n",
        "        :type modelfile: str\n",
        "        :return: list (DependencyGraph) with the 'head' and 'rel' information\n",
        "        \"\"\"\n",
        "        result = []\n",
        "        # First load the model\n",
        "        model = pickle.load(open(modelFile, \"rb\"))\n",
        "        operation = Transition(self._algorithm)\n",
        "\n",
        "        for depgraph in depgraphs:\n",
        "            conf = NxtConfiguration(depgraph)\n",
        "            while len(conf.buffer) > 0:\n",
        "                x_test = self._convert_to_binary_features(conf.extract_features()).reshape(1, -1)\n",
        "                # y_proba = np.squeeze(model.predict_proba(x_test))\n",
        "                # y_classes = model.classes_[np.flip(np.argsort(y_proba))]\n",
        "                # # From the prediction match to the operation\n",
        "                # y_classes = self._label_encoder.inverse_transform(y_classes)\n",
        "                # Note that SHIFT is always a valid operation\n",
        "\n",
        "                y_pred = model.predict(x_test)\n",
        "                y_class = np.squeeze(self._label_encoder.inverse_transform(y_pred)).item()\n",
        "                \n",
        "                baseTransition = y_class.split(\":\")[0]\n",
        "                \n",
        "                operationExecuted = False\n",
        "\n",
        "                if baseTransition == Transition.LEFT_ARC:\n",
        "                    if (operation.left_arc(conf, y_class.split(\":\")[1]) != -1):\n",
        "                        operationExecuted = True\n",
        "                if baseTransition == Transition.RIGHT_ARC:\n",
        "                    if (operation.right_arc(conf, y_class.split(\":\")[1]) != -1):\n",
        "                        operationExecuted = True\n",
        "                if baseTransition == Transition.REDUCE:\n",
        "                    if operation.reduce(conf) != -1:\n",
        "                        operationExecuted = True\n",
        "                if baseTransition == Transition.SHIFT or not operationExecuted:\n",
        "                    operation.shift(conf)\n",
        "\n",
        "                # for y_pred in y_classes:\n",
        "\n",
        "                #     baseTransition = y_pred.split(\":\")[0]\n",
        "\n",
        "                #     if baseTransition == Transition.LEFT_ARC:\n",
        "                #         if (operation.left_arc(conf, y_pred.split(\":\")[1]) != -1):\n",
        "                #             break\n",
        "                #     elif baseTransition == Transition.RIGHT_ARC:\n",
        "                #         if (operation.right_arc(conf, y_pred.split(\":\")[1]) != -1):\n",
        "                #             break\n",
        "                #     elif baseTransition == Transition.REDUCE:\n",
        "                #         if operation.reduce(conf) != -1:\n",
        "                #             break\n",
        "                #     elif baseTransition == Transition.SHIFT:\n",
        "                #         if operation.shift(conf) != -1:\n",
        "                #             break\n",
        "            # Finish with operations build the dependency graph from Conf.arcs\n",
        "\n",
        "            new_depgraph = deepcopy(depgraph)\n",
        "            for key in new_depgraph.nodes:\n",
        "                node = new_depgraph.nodes[key]\n",
        "                node[\"rel\"] = \"\"\n",
        "                # With the default, all the token depend on the Root\n",
        "                node[\"head\"] = 0\n",
        "            for (head, rel, child) in conf.arcs:\n",
        "                c_node = new_depgraph.nodes[child]\n",
        "                c_node[\"head\"] = head\n",
        "                c_node[\"rel\"] = rel\n",
        "            result.append(new_depgraph)\n",
        "\n",
        "        return result\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxNM30apQcYz"
      },
      "source": [
        "### Task B2\n",
        "Evaluate the features, comparing the performance to the original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S90zVZbYPBb0"
      },
      "source": [
        "VALIDATION_COUNT = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q49Nt-NEUSna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448b90e9-6831-4c24-f7a4-8cbe052b0444"
      },
      "source": [
        "# Standard Transition Parser\n",
        "std_tp = TransitionParser('arc-eager')\n",
        "\n",
        "TRAINING_COUNT = 100\n",
        "\n",
        "std_tp.train(dependency_treebank.parsed_sents()[:TRAINING_COUNT], 'tp.std-model')\n",
        "\n",
        "# Performances\n",
        "parses = std_tp.parse(dependency_treebank.parsed_sents()[-VALIDATION_COUNT:], 'tp.std-model')\n",
        "de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-VALIDATION_COUNT:])\n",
        "std_uas = de.eval()[1]\n",
        "print(f\"Original parser: {std_uas}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Number of training examples : 100\n",
            " Number of valid (projective) examples : 100\n",
            "[LibSVM]Original parser: 0.750459981600736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxJdZJ3MTeIv",
        "outputId": "62d0ace6-6832-40b5-ea7a-1049d77a1e7b"
      },
      "source": [
        "# Advanced Transition Parser with SVM Classifier\n",
        "nxt_tp = NxtTransitionParser('svm')\n",
        "\n",
        "TRAINING_COUNT = 100\n",
        "\n",
        "nxt_tp.train(dependency_treebank.parsed_sents()[:TRAINING_COUNT], 'tp.nxt-model')\n",
        "\n",
        "parses = nxt_tp.parse(dependency_treebank.parsed_sents()[-VALIDATION_COUNT:], 'tp.nxt-model')\n",
        "de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-VALIDATION_COUNT:])\n",
        "std_uas = de.eval()[1]\n",
        "print(f\"Advanced (SVM) parser: {std_uas}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Advanced (SVM) parser: 0.5278288868445262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_Mbki3u_Zkc",
        "outputId": "6551a8bb-8b16-45cb-dc07-6348d39a6ce5"
      },
      "source": [
        "# Advanced Transition Parser with MLP Classifier\n",
        "nxt_tp = NxtTransitionParser('mlp')\n",
        "\n",
        "TRAINING_COUNT = 100\n",
        "\n",
        "nxt_tp.train(dependency_treebank.parsed_sents()[:TRAINING_COUNT], 'tp.std-model')\n",
        "\n",
        "parses = nxt_tp.parse(dependency_treebank.parsed_sents()[-VALIDATION_COUNT:], 'tp.std-model')\n",
        "de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-VALIDATION_COUNT:])\n",
        "std_uas = de.eval()[1]\n",
        "print(f\"Advanced (MLP) parser: {std_uas}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Advanced (MLP) parser: 0.5363385464581417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlhtXzQ2FeiK",
        "outputId": "c0e61737-2bec-4c89-d41c-74098f8ed996"
      },
      "source": [
        "# Advanced Transition Parser with MLP Classifier\n",
        "nxt_tp = NxtTransitionParser('mlp')\n",
        "\n",
        "TRAINING_COUNT = len(dependency_treebank.parsed_sents()) - VALIDATION_COUNT\n",
        "\n",
        "nxt_tp.train(dependency_treebank.parsed_sents()[:TRAINING_COUNT], 'tp.std-model')\n",
        "\n",
        "parses = nxt_tp.parse(dependency_treebank.parsed_sents()[-VALIDATION_COUNT:], 'tp.std-model')\n",
        "de = DependencyEvaluator(parses, dependency_treebank.parsed_sents()[-VALIDATION_COUNT:])\n",
        "std_uas = de.eval()[1]\n",
        "print(f\"Advanced (MLP) parser: {std_uas}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Advanced (MLP) parser: 0.7902483900643974\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}